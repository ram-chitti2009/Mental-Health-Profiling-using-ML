{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dca6c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: opendatasets in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (0.1.22)\n",
      "Requirement already satisfied: bleach in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (2025.10.5)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (3.4.4)\n",
      "Requirement already satisfied: idna in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (3.11)\n",
      "Requirement already satisfied: protobuf in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (6.33.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: click in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from opendatasets) (8.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\venka\\desktop\\mental-health-profiling\\venv\\lib\\site-packages (from click->opendatasets) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for working with Kaggle datasets\n",
    "%pip install kaggle opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b9658a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/thedevastator/medical-student-mental-health\n",
      "Dataset downloaded successfully!\n",
      "Dataset downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "import os \n",
    "kaggle.api.dataset_download_files('osmi/mental-health-in-tech-survey', \n",
    "                                  path='./data', \n",
    "                                  unzip=True)\n",
    "\n",
    "print(\"Dataset downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d5e2895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the data directory:\n",
      "- ./data\\Codebook Carrard et al. 2022 MedTeach.csv\n",
      "- ./data\\Data Carrard et al. 2022 MedTeach.csv\n",
      "\n",
      "Trying to load: ./data\\Codebook Carrard et al. 2022 MedTeach.csv\n",
      "Skipping codebook file\n",
      "\n",
      "Trying to load: ./data\\Data Carrard et al. 2022 MedTeach.csv\n",
      "Successfully loaded: ./data\\Data Carrard et al. 2022 MedTeach.csv\n",
      "Shape: (886, 20)\n",
      "Columns: ['id', 'age', 'year', 'sex', 'glang', 'part', 'job', 'stud_h', 'health', 'psyt', 'jspe', 'qcae_cog', 'qcae_aff', 'amsp', 'erec_mean', 'cesd', 'stai_t', 'mbi_ex', 'mbi_cy', 'mbi_ea']\n",
      "\n",
      "First 5 rows:\n",
      "   id  age  year  sex  glang  part  job  stud_h  health  psyt  jspe  qcae_cog  \\\n",
      "0   2   18     1    1    120     1    0      56       3     0    88        62   \n",
      "1   4   26     4    1      1     1    0      20       4     0   109        55   \n",
      "2   9   21     3    2      1     0    0      36       3     0   106        64   \n",
      "3  10   21     2    2      1     0    1      51       5     0   101        52   \n",
      "4  13   21     3    1      1     1    0      22       4     0   102        58   \n",
      "\n",
      "   qcae_aff  amsp  erec_mean  cesd  stai_t  mbi_ex  mbi_cy  mbi_ea  \n",
      "0        27    17   0.738095    34      61      17      13      20  \n",
      "1        37    22   0.690476     7      33      14      11      26  \n",
      "2        39    17   0.690476    25      73      24       7      23  \n",
      "3        33    18   0.833333    17      48      16      10      21  \n",
      "4        28    21   0.690476    14      46      22      14      23  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os \n",
    "\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "data_files = glob.glob('./data/*')\n",
    "print(\"Files in the data directory:\")\n",
    "for file in data_files:\n",
    "    print(f\"- {file}\")\n",
    "\n",
    "df = None\n",
    "for file in data_files:\n",
    "    if file.endswith('.csv'):\n",
    "        try:\n",
    "            print(f\"\\nTrying to load: {file}\")\n",
    "            \n",
    "            if 'codebook' in file.lower():\n",
    "                print(\"Skipping codebook file\")\n",
    "                continue\n",
    "            elif 'data' in file.lower():\n",
    "                df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n",
    "                print(f\"Successfully loaded: {file}\")\n",
    "                print(f\"Shape: {df.shape}\")\n",
    "                print(f\"Columns: {df.columns.tolist()}\")\n",
    "                \n",
    "            else:\n",
    "                df = pd.read_csv(file, encoding='utf-8', on_bad_lines='skip')\n",
    "                print(f\"Successfully loaded: {file}\")\n",
    "                print(f\"Shape: {df.shape}\")\n",
    "                print(f\"Columns: {df.columns.tolist()}\")\n",
    "                \n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(\"No dataset could be loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d4532a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found for D1-Swiss: data\\Data Carrard et al. 2022 MedTeach.csv\n",
      "Loaded D2-Cultural dataset with shape: (101, 11)\n",
      "Converting categorical column Depression to numerical in D2-Cultural\n",
      "Converting categorical column Anxiety to numerical in D2-Cultural\n",
      "Converting categorical column Burnout to numerical in D2-Cultural\n",
      "Converting categorical column Stress to numerical in D2-Cultural\n",
      "Loaded D3-Academic dataset with shape: (27901, 18)\n",
      "Converting categorical column Stress to numerical in D3-Academic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_13988\\454259741.py:94: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_selected[col] = df_selected[col].astype(str).str.lower().replace(\n",
      "C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_13988\\454259741.py:94: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_selected[col] = df_selected[col].astype(str).str.lower().replace(\n",
      "C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_13988\\454259741.py:94: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_selected[col] = df_selected[col].astype(str).str.lower().replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded D4-Tech dataset with shape: (1259, 27)\n",
      "Converting categorical column Depression to numerical in D4-Tech\n",
      "Converting categorical column Anxiety to numerical in D4-Tech\n",
      "Converting categorical column Burnout to numerical in D4-Tech\n",
      "\n",
      "Datasets with missing files or errors:\n",
      "- D1-Swiss\n",
      "\n",
      "Combined dataset shape: (29261, 6)\n",
      "\n",
      "Data Cleaning: Handling missing values\n",
      "\n",
      "Normalizing Universal Features using Z-score normalization\n",
      "Normalization complete. Scaler saved as 'universal_features_scaler.joblib'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_13988\\454259741.py:94: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_selected[col] = df_selected[col].astype(str).str.lower().replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fused dataset saved as 'fused_mental_health_dataset.csv'\n",
      "Skipping save for D1-Swiss because it has no processed rows.\n",
      "D2-Cultural processed dataset saved as 'D2_Cultural_processed.csv'\n",
      "D3-Academic processed dataset saved as 'D3_Academic_processed.csv'\n",
      "D4-Tech processed dataset saved as 'D4_Tech_processed.csv'\n",
      "\n",
      "Data processing complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "DATA_DIR = Path(\"./data\")\n",
    "\n",
    "FILE_PATHS = {\n",
    "    \"D1-Swiss\": \"Data Carrard et al. 2022 MedTeach.csv\",\n",
    "    \"D2-Cultural\": \"d2_Malaysian.csv\",\n",
    "    \"D3-Academic\": \"d3_Indian.csv\",\n",
    "    \"D4-Tech\": \"d4_tech_workers.csv\",\n",
    "}\n",
    "\n",
    "OUTPUT_PATHS = {\n",
    "    \"D1-Swiss\": \"D1_Swiss_processed.csv\",\n",
    "    \"D2-Cultural\": \"D2_Cultural_processed.csv\",\n",
    "    \"D3-Academic\": \"D3_Academic_processed.csv\",\n",
    "    \"D4-Tech\": \"D4_Tech_processed.csv\",\n",
    "}\n",
    "\n",
    "COLUMN_MAPPING = {\n",
    "    \"D1-Swiss\": {\n",
    "        \"cesd\": \"Depression\",\n",
    "        \"stai_t\": \"Anxiety\",\n",
    "        \"mbi_ex\": \"Burnout\",\n",
    "        \"mbi_cy\": \"Stress\",\n",
    "        \"psyt\": \"PSYT_Therapy_Use\",\n",
    "    },\n",
    "    \"D2-Cultural\": {\n",
    "        \"Do you have Depression?\": \"Depression\",\n",
    "        \"Do you have Anxiety?\": \"Anxiety\",\n",
    "        \"Do you have Panic attack?\": \"Burnout\",\n",
    "        \"Your current year of Study\": \"Stress\",\n",
    "    },\n",
    "    \"D3-Academic\": {\n",
    "        \"Depression\": \"Depression\",\n",
    "        \"Academic Pressure\": \"Anxiety\",\n",
    "        \"Study Satisfaction\": \"Burnout\",\n",
    "        \"Financial Stress\": \"Stress\",\n",
    "    },\n",
    "    \"D4-Tech\": {\n",
    "        \"mental_health_consequence\": \"Depression\",\n",
    "        \"work_interfere\": \"Anxiety\",\n",
    "        \"leave\": \"Burnout\",\n",
    "        \"Age\": \"Stress\",\n",
    "        \"treatment\": \"H3_Tech_Validation\",\n",
    "    },\n",
    "}\n",
    "\n",
    "UNIVERSAL_FEATURES = [\"Depression\", \"Anxiety\", \"Burnout\", \"Stress\"]\n",
    "\n",
    "all_data_frames = []\n",
    "missing_sources = []\n",
    "\n",
    "for source_name, file_name in FILE_PATHS.items():\n",
    "    file_path = DATA_DIR / file_name\n",
    "\n",
    "    if not file_path.exists():\n",
    "        print(f\"File not found for {source_name}: {file_path}\")\n",
    "        missing_sources.append(source_name)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df_raw = pd.read_csv(file_path, encoding=\"utf-8\", on_bad_lines=\"skip\")\n",
    "        print(f\"Loaded {source_name} dataset with shape: {df_raw.shape}\")\n",
    "\n",
    "        current_mapping = COLUMN_MAPPING[source_name]\n",
    "        missing_cols = [src for src in current_mapping if src not in df_raw.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"ERROR: Missing crucial columns in {file_name}: {missing_cols}\")\n",
    "            missing_sources.append(source_name)\n",
    "            continue\n",
    "\n",
    "        df_named = df_raw.rename(columns=current_mapping)\n",
    "\n",
    "        selected_columns = UNIVERSAL_FEATURES.copy()\n",
    "        if \"PSYT_Therapy_Use\" in current_mapping.values():\n",
    "            selected_columns.append(\"PSYT_Therapy_Use\")\n",
    "        if \"H3_Tech_Validation\" in current_mapping.values():\n",
    "            selected_columns.append(\"H3_Tech_Validation\")\n",
    "\n",
    "        for col in selected_columns:\n",
    "            if col not in df_named.columns:\n",
    "                df_named[col] = np.nan\n",
    "\n",
    "        df_selected = df_named[selected_columns].copy()\n",
    "\n",
    "        for col in UNIVERSAL_FEATURES:\n",
    "            if df_selected[col].dtype == \"object\":\n",
    "                print(f\"Converting categorical column {col} to numerical in {source_name}\")\n",
    "                df_selected[col] = df_selected[col].astype(str).str.lower().replace(\n",
    "                    {\n",
    "                        \"yes\": 1,\n",
    "                        \"no\": 0,\n",
    "                        \"often\": 1,\n",
    "                        \"rarely\": 0,\n",
    "                        \"sometimes\": 0.5,\n",
    "                        \"maybe\": 0.5,\n",
    "                        \"most of the time\": 1,\n",
    "                        \"never\": 0,\n",
    "                        \"always\": 1,\n",
    "                        \"not sure\": 0.5,\n",
    "                        \"high\": 1,\n",
    "                        \"low\": 0,\n",
    "                        \"medium\": 0.5,\n",
    "                        \"somewhat easy\": 0.5,\n",
    "                        \"somewhat difficult\": 0.5,\n",
    "                        \"very difficult\": 1,\n",
    "                        \"very easy\": 0,\n",
    "                    }\n",
    "                )\n",
    "                df_selected[col] = pd.to_numeric(df_selected[col], errors=\"coerce\")\n",
    "\n",
    "        df_selected[\"Source_Group\"] = source_name\n",
    "        all_data_frames.append(df_selected)\n",
    "\n",
    "    except Exception as exc:\n",
    "        print(f\"Error loading {source_name} dataset: {exc}\")\n",
    "        missing_sources.append(source_name)\n",
    "\n",
    "if not all_data_frames:\n",
    "    print(\"No datasets were processed. Exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if missing_sources:\n",
    "    print(\"\\nDatasets with missing files or errors:\")\n",
    "    for name in missing_sources:\n",
    "        print(f\"- {name}\")\n",
    "\n",
    "df_combined = pd.concat(all_data_frames, ignore_index=True)\n",
    "print(f\"\\nCombined dataset shape: {df_combined.shape}\")\n",
    "\n",
    "print(\"\\nData Cleaning: Handling missing values\")\n",
    "for feature in UNIVERSAL_FEATURES:\n",
    "    mean_value = df_combined[feature].mean(skipna=True)\n",
    "    df_combined[feature] = df_combined[feature].fillna(mean_value)\n",
    "\n",
    "print(\"\\nNormalizing Universal Features using Z-score normalization\")\n",
    "scaler = StandardScaler()\n",
    "df_combined[UNIVERSAL_FEATURES] = scaler.fit_transform(df_combined[UNIVERSAL_FEATURES])\n",
    "joblib.dump(scaler, \"universal_features_scaler.joblib\")\n",
    "print(\"Normalization complete. Scaler saved as 'universal_features_scaler.joblib'.\")\n",
    "\n",
    "fused_output = \"fused_mental_health_dataset.csv\"\n",
    "df_combined.to_csv(fused_output, index=False)\n",
    "print(f\"\\nFused dataset saved as '{fused_output}'\")\n",
    "\n",
    "for source_name, output_file in OUTPUT_PATHS.items():\n",
    "    df_subset = df_combined[df_combined[\"Source_Group\"] == source_name]\n",
    "    if df_subset.empty:\n",
    "        print(f\"Skipping save for {source_name} because it has no processed rows.\")\n",
    "        continue\n",
    "    df_subset.to_csv(output_file, index=False)\n",
    "    print(f\"{source_name} processed dataset saved as '{output_file}'\")\n",
    "\n",
    "print(\"\\nData processing complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
